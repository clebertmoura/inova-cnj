{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import das bibliotecas\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from os.path import isfile, isdir, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars file:///home/jovyan/jdbc/postgresql-42.2.17.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_host = os.getenv('POSTGRES_HOST')\n",
    "db_port = os.getenv('POSTGRES_PORT')\n",
    "db_name = os.getenv('POSTGRES_DB')\n",
    "db_user = os.getenv('POSTGRES_USER')\n",
    "db_pass = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "db_driver = \"org.postgresql.Driver\"\n",
    "db_url = \"jdbc:postgresql://\"+db_host+\":\"+db_port+\"/\" + db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quando for True, as tabelas das dimensões serão recriadas e carregadas\n",
    "carregar_dimensoes = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialização do spark\n",
    "conf = SparkConf() \\\n",
    "        .setMaster(\"local[*]\") \\\n",
    "        .setAppName(\"ETL-CarregarDadosNasDimensoes\") \\\n",
    "        .set(\"spark.executor.memory\", \"8g\") \\\n",
    "        .set(\"spark.driver.memory\", \"8g\") \\\n",
    "        .set(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "        .set(\"spark.ui.enabled\", \"true\") \\\n",
    "        .set(\"spark.sql.shuffle.partitions\" , \"800\") \\\n",
    "        .set(\"spark.sql.execution.arrow.pyspark.enabled\" , \"false\") \\\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o schema dos dados para leitura dos arquivos JSON\n",
    "schema = StructType([\n",
    "    StructField(\"dadosBasicos\", StructType([\n",
    "        StructField(\"assunto\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"assuntoLocal\", StructType([\n",
    "                    StructField(\"codigoAssunto\", LongType(), True),\n",
    "                    StructField(\"codigoPaiNacional\", LongType(), True),\n",
    "                    StructField(\"descricao\", StringType(), True)\n",
    "                ]), True),\n",
    "                StructField(\"codigoNacional\", LongType(), True),\n",
    "                StructField(\"principal\", BooleanType(), True)\n",
    "            ]),\n",
    "        ), True),\n",
    "        StructField('classeProcessual', LongType(), True),\n",
    "        StructField('codigoLocalidade', StringType(), True),\n",
    "        StructField('competencia', StringType(), True),\n",
    "        StructField('dataAjuizamento', StringType(), True),\n",
    "        StructField('dscSistema', StringType(), True),\n",
    "        StructField('nivelSigilo', LongType(), True),\n",
    "        StructField('numero', StringType(), True),\n",
    "        StructField(\"orgaoJulgador\", StructType([\n",
    "            StructField(\"codigoMunicipioIBGE\", LongType(), True),\n",
    "            StructField(\"codigoOrgao\", StringType(), True),\n",
    "            StructField(\"instancia\", StringType(), True),\n",
    "            StructField(\"nomeOrgao\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField('procEl', LongType(), True),\n",
    "        StructField(\"tamanhoProcesso\", StringType(), True),\n",
    "        StructField(\"totalAssuntos\", LongType(), True),\n",
    "        StructField(\"valorCausa\", StringType(), True)       \n",
    "    ]), True),\n",
    "    StructField(\"grau\", StringType(), True),\n",
    "    StructField(\"millisInsercao\", LongType(), True),\n",
    "    StructField(\"movimento\", ArrayType(     \n",
    "        StructType([\n",
    "            StructField(\"complementoNacional\", ArrayType(\n",
    "                StructType([\n",
    "                    StructField(\"codComplemento\", LongType(), True),\n",
    "                    StructField(\"codComplementoTabelado\", LongType(), True),\n",
    "                    StructField(\"descricaoComplemento\", StringType(), True),\n",
    "                ])\n",
    "            ), True),\n",
    "            StructField(\"dataHora\", StringType(), True),\n",
    "            StructField(\"idDocumentoVinculado\", ArrayType(\n",
    "                StringType(),\n",
    "            ), True),\n",
    "            StructField(\"identificadorMovimento\", StringType(), True),\n",
    "            StructField(\"movimentoLocal\", StructType([\n",
    "                StructField('codigoMovimento', LongType(), True),\n",
    "                StructField('codigoPaiNacional', LongType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"movimentoNacional\", StructType([\n",
    "                StructField('codigoNacional', LongType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"nivelSigilo\", StringType(), True),\n",
    "            StructField(\"orgaoJulgador\", StructType([\n",
    "                StructField(\"codigoMunicipioIBGE\", LongType(), True),\n",
    "                StructField(\"codigoOrgao\", StringType(), True),\n",
    "                StructField(\"instancia\", StringType(), True),\n",
    "                StructField(\"nomeOrgao\", StringType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"tipoDecisao\", StringType(), True),\n",
    "            StructField(\"tipoResponsavelMovimento\", StringType(), True)\n",
    "        ]),\n",
    "    ), True),\n",
    "    StructField(\"siglaTribunal\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabela inovacnj.classe criada.\n"
     ]
    }
   ],
   "source": [
    "# carrega o CSV de classes e faz a carga da dimensão\n",
    "df_classes = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_classes.csv\")\n",
    "\n",
    "df_classes.createOrReplaceTempView(\"classes\")\n",
    "   \n",
    "df_qry_classes = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"sigla,\" + \n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM classes \"\n",
    ")\n",
    "\n",
    "if carregar_dimensoes :\n",
    "    df_qry_classes.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.classe\") \\\n",
    "        .save()\n",
    "\n",
    "print(\"tabela inovacnj.classe criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabela inovacnj.assunto criada.\n"
     ]
    }
   ],
   "source": [
    "# carrega o CSV de assuntos e faz a carga da dimensão\n",
    "df_assuntos = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_assuntos.csv\")\n",
    "\n",
    "df_assuntos.createOrReplaceTempView(\"assuntos\")\n",
    "   \n",
    "df_qry_assuntos = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM assuntos \"\n",
    ")\n",
    "\n",
    "if carregar_dimensoes :\n",
    "    df_qry_assuntos.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.assunto\") \\\n",
    "        .save()\n",
    "\n",
    "print(\"tabela inovacnj.assunto criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabela inovacnj.movimentocnj criada.\n"
     ]
    }
   ],
   "source": [
    "# carrega o CSV de movimentos e faz a carga da dimensão\n",
    "df_movimentos = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/sgt_movimentos.csv\")\n",
    "\n",
    "# cria uma view temporaria dos movimentos\n",
    "df_movimentos.createOrReplaceTempView(\"movimentos\")\n",
    "\n",
    "df_qry_movimentos = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"codigo AS cod,\" + \n",
    "    \"descricao,\" + \n",
    "    \"cod_pai AS codpai \" +    \n",
    "    \"FROM movimentos \"\n",
    ")\n",
    "\n",
    "if carregar_dimensoes :\n",
    "    df_qry_movimentos.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.movimentocnj\") \\\n",
    "        .save()\n",
    "\n",
    "print(\"tabela inovacnj.movimentocnj criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabela inovacnj.grau_jurisdicao criada.\n"
     ]
    }
   ],
   "source": [
    "# carrega o CSV de grau de jurisdição\n",
    "\n",
    "df_graujur = spark.read \\\n",
    ".option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/grau_jurisdicao.csv\")\n",
    "\n",
    "df_graujur.createOrReplaceTempView(\"graujur\")\n",
    "df_graujur = spark.sql(\"SELECT cod as cod, \" +\n",
    "                               \"descricao \" +\n",
    "                           \"FROM graujur \"\n",
    "                      )\n",
    "\n",
    "df_graujur.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.grau_jurisdicao\") \\\n",
    "        .save()\n",
    "\n",
    "print(\"tabela inovacnj.grau_jurisdicao criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o CSV de serventia e faz a carga da dimensão\n",
    "df_serventias = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\";\") \\\n",
    "    .csv(\"./base/mpm_serventias.csv\")\n",
    "\n",
    "df_serventias.createOrReplaceTempView(\"serventias\")\n",
    "\n",
    "df_qry_serventias = spark.sql(\n",
    "    \"SELECT \" +\n",
    "    \"SEQ_ORGAO AS cod, \" + \n",
    "    \"DSC_ORGAO AS descricao, \" + \n",
    "    \"SEQ_ORGAO_PAI AS codpai, \" + \n",
    "    \"TIP_ORGAO AS sigla_tipoj, \" + \n",
    "    \"DSC_TIP_ORGAO AS tipo_oj, \" + \n",
    "    \"DSC_CIDADE AS cidade, \" + \n",
    "    \"SIG_UF AS uf, \" + \n",
    "    \"COD_IBGE AS codibge, \" + \n",
    "    \"TIP_ESFERA_JUSTICA AS esfera \" + \n",
    "    \"FROM serventias \"\n",
    ")\n",
    "\n",
    "if carregar_dimensoes :\n",
    "    df_qry_serventias.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.orgao_julgador\") \\\n",
    "        .save()\n",
    "\n",
    "    print(\"tabela inovacnj.orgao_julgador criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega o CSV de tribunal e faz a carga da dimensão\n",
    "df_tribunais = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .option(\"inferSchema\",\"true\") \\\n",
    "    .option(\"delimiter\",\",\") \\\n",
    "    .csv(\"./base/tribunal.csv\")\n",
    "\n",
    "df_tribunais.createOrReplaceTempView(\"tribunais\")\n",
    "\n",
    "df_qry_df_tribunais = spark.sql(\n",
    "    \"SELECT * \" +\n",
    "    \"FROM tribunais \"\n",
    ")\n",
    "\n",
    "if carregar_dimensoes :\n",
    "    df_qry_df_tribunais.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "        .option(\"dbtable\", \"inovacnj.tribunal\") \\\n",
    "        .save()\n",
    "\n",
    "    print(\"tabela inovacnj.tribunal criada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qry_classes = df_qry_classes.withColumnRenamed(\"descricao\", \"descclasse\")\n",
    "df_qry_movimentos = df_qry_movimentos.withColumnRenamed(\"descricao\", \"descmovimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramos = {'./base/justica_eleitoral': 'jele', './base/justica_estadual': 'jest', \\\n",
    "         './base/justica_federal': 'jfed', './base/justica_militar': 'jmil', \\\n",
    "         './base/justica_trabalho': 'jtra'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carregamento do ramo de justica: ./base/justica_federal\n",
      "Sufixo tabela para ramo de justica: jfed\n",
      "Iniciando carregamento do tribunal: ./base/justica_federal/processos-trf4\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_9.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_11.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_5.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_4.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_10.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_8.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_3.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_2.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_1.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_7.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_12.json\n",
      "Carregando dataframe do arquivo: ./base/justica_federal/processos-trf4/processos-trf4_6.json\n",
      "Finalizando carregamento do tribunal: ./base/justica_federal/processos-trf4\n",
      "Finalizando carregamento do ramo de justica: ./base/justica_federal\n",
      "Carregamento dos arquivos finalizado.\n"
     ]
    }
   ],
   "source": [
    "# faz o carregamento de todos os arquivos em um único DataFrame,\n",
    "# geracao do CSV com os dados consolidados\n",
    "# cria a tabela fato com os movimentos processuais\n",
    "\n",
    "basedir = \"./base\"\n",
    "\n",
    "dirs_ramos_justica = [join(basedir, f) for f in os.listdir(basedir) if isdir(join(basedir, f))]\n",
    "\n",
    "is_first = True\n",
    "\n",
    "for dir_ramo_just in dirs_ramos_justica:\n",
    "    print(\"Iniciando carregamento do ramo de justica: \" + dir_ramo_just)\n",
    "    sufixo_tabela = ramos.get(dir_ramo_just, 'default')\n",
    "    print(\"Sufixo tabela para ramo de justica: \" + sufixo_tabela)\n",
    "    dirs_tribunais = [join(dir_ramo_just, f) for f in os.listdir(dir_ramo_just) if isdir(join(dir_ramo_just, f))]\n",
    "    \n",
    "    for dir_trib in dirs_tribunais:\n",
    "        print(\"Iniciando carregamento do tribunal: \" + dir_trib)\n",
    "        \n",
    "        arquivos = [join(dir_trib, f) for f in os.listdir(dir_trib) if isfile(join(dir_trib, f))]\n",
    "        \n",
    "        df_union_tribunal = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "        \n",
    "        for arq in arquivos:\n",
    "            if arq.endswith(\".DS_Store\") :\n",
    "                continue\n",
    "                \n",
    "            print(\"Carregando dataframe do arquivo: \" + arq)\n",
    "            df = spark.read.schema(schema).json(arq)\n",
    "            df_union_tribunal = df_union_tribunal.union(df)\n",
    "        \n",
    "        # Cria uma view temporaria para o dataframe\n",
    "        df_union_tribunal.createOrReplaceTempView(\"proc_movimentos\")\n",
    "        \n",
    "        \n",
    "        # Query para carregar os assuntos dos processos na dimensão: inovacnj.processo_assunto\n",
    "        df_query_processo_assunto = spark.sql(\n",
    "            \"SELECT DISTINCT \" + \n",
    "            \"siglaTribunal AS codtribunal, \" + \n",
    "            \"dadosBasicos.numero AS npu, \" + \n",
    "            \"to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') AS dtajuizamento, \"\n",
    "            \"dadosBasicos.classeProcessual AS codclasse, \" +\n",
    "            \n",
    "            \"coalesce(exp_assunto.assunto.codigoNacional, exp_assunto.assunto.codigoNacional, -1) AS codassunto, \" +\n",
    "            \"exp_assunto.assunto.principal AS assunto_principal, \" + \n",
    "            \"coalesce(exp_assunto.assunto.assuntoLocal.codigoAssunto, exp_assunto.assunto.assuntoLocal.codigoAssunto, -1) AS codassunto_local, \" +\n",
    "            \"coalesce(exp_assunto.assunto.assuntoLocal.codigoPaiNacional, exp_assunto.assunto.assuntoLocal.codigoPaiNacional, -1) AS codassunto_pai, \" +\n",
    "            \"exp_assunto.assunto.assuntoLocal.descricao AS descassunto_local \" +\n",
    "            \n",
    "            \"FROM proc_movimentos \" + \n",
    "            \"LATERAL VIEW explode(dadosBasicos.assunto) exp_assunto as assunto \" +\n",
    "            \"WHERE cast(substring(dadosBasicos.dataAjuizamento,0,4) as INT) >= 2000 AND to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') >= to_timestamp('20000101000000', 'yyyyMMddHHmmss') \"\n",
    "        )\n",
    "        \n",
    "        df_query_processo_assunto = df_query_processo_assunto \\\n",
    "           .join(df_qry_classes, df_query_processo_assunto[\"codclasse\"] == df_qry_classes[\"cod\"], \"left\") \\\n",
    "           .join(df_qry_assuntos, df_query_processo_assunto[\"codassunto\"] == df_qry_assuntos[\"cod\"], \"left\") \\\n",
    "           .select( \\\n",
    "                col(\"codtribunal\"), col(\"npu\"), col(\"dtajuizamento\"), \\\n",
    "                col(\"codclasse\"), col(\"descclasse\"), \\\n",
    "                col(\"codassunto\"), col(\"descricao\").alias(\"descassunto\"), \\\n",
    "                col(\"assunto_principal\"), col(\"codassunto_local\"), col(\"descassunto_local\"), col(\"codassunto_pai\") \\\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Query para formato em CSV\n",
    "        df_query_processo_movimento = spark.sql(\n",
    "            \"SELECT DISTINCT \" + \n",
    "            \"siglaTribunal AS codtribunal, \" + \n",
    "            \"grau, \" +\n",
    "            \"millisinsercao, \" +\n",
    "\n",
    "            \"dadosBasicos.classeProcessual AS codclasse, \" +\n",
    "            \"dadosBasicos.codigoLocalidade AS codlocalidade, \" +\n",
    "            \"coalesce(dadosBasicos.competencia, dadosBasicos.competencia, -1) as competencia, \" +\n",
    "            \"to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') AS dtajuizamento, \"\n",
    "            \"dadosBasicos.dscSistema AS descsistema, \" +\n",
    "            \"dadosBasicos.nivelSigilo AS nivelsigilo, \" +\n",
    "            \"dadosBasicos.numero AS npu, \" + \n",
    "            \"dadosBasicos.orgaoJulgador.codigoMunicipioIBGE AS oj_codibge, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.codigoOrgao AS oj_cod, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.instancia AS oj_instancia, \" +\n",
    "            \"dadosBasicos.orgaoJulgador.nomeOrgao AS oj_descricao, \" +\n",
    "            \"dadosBasicos.procEl AS tramitacao, \" +\n",
    "            \"dadosBasicos.tamanhoProcesso AS tamanhoprocesso, \" +\n",
    "            \"dadosBasicos.valorCausa AS valorcausa, \" +\n",
    "\n",
    "            \"exp_movimento.movimento.dataHora AS mov_dtmov, \" +\n",
    "            \"exp_movimento.movimento.nivelSigilo AS mov_nivelsigilo, \" +\n",
    "            \"exp_movimento.movimento.movimentoNacional.codigoNacional AS mov_cod, \" +\n",
    "            \"exp_movimento.movimento.movimentoLocal.codigoMovimento AS mov_codlocal, \" +\n",
    "            \"exp_movimento.movimento.movimentoLocal.codigoPaiNacional AS mov_codpainacional, \" +\n",
    "\n",
    "            \"exp_movimento.movimento.orgaoJulgador.codigoMunicipioIBGE as mov_oj_codibge, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.codigoOrgao as mov_oj_cod, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.instancia as mov_oj_instancia, \" +\n",
    "            \"exp_movimento.movimento.orgaoJulgador.nomeOrgao as mov_oj_descricao, \" +\n",
    "\n",
    "            \"coalesce(exp_movimento.movimento.tipoDecisao, exp_movimento.movimento.tipoDecisao, -1) as mov_tpdecisao, \" +\n",
    "            \"coalesce(exp_movimento.movimento.tipoResponsavelMovimento, exp_movimento.movimento.tipoResponsavelMovimento, -1) as mov_tprespmov \" +\n",
    "\n",
    "            \"FROM proc_movimentos \" + \n",
    "            \"LATERAL VIEW explode(movimento) exp_movimento as movimento \" + \n",
    "            \"WHERE cast(substring(dadosBasicos.dataAjuizamento,0,4) as INT) >= 2000 AND to_timestamp(dadosBasicos.dataAjuizamento, 'yyyyMMddHHmmss') >= to_timestamp('20000101000000', 'yyyyMMddHHmmss') \" + \n",
    "            \"AND exp_movimento.movimento.movimentoNacional.codigoNacional NOT IN(581, 85, 12270, 12271) \" + \n",
    "            \"AND size(proc_movimentos.movimento) > 0 \"\n",
    "            #\"AND (proc_movimentos.movimento[0].movimentoNacional.codigoNacional IN (26, 12474) \" +\n",
    "            #\"AND proc_movimentos.movimento[size(proc_movimentos.movimento) -1].movimentoNacional.codigoNacional IN (22, 246)) \"\n",
    "        )\n",
    "        \n",
    "        df_query_processo_movimento = df_query_processo_movimento \\\n",
    "           .join(df_qry_movimentos, df_query_processo_movimento[\"mov_cod\"] == df_qry_movimentos[\"cod\"], \"left\") \\\n",
    "           .join(df_qry_classes, df_query_processo_movimento[\"codclasse\"] == df_qry_classes[\"cod\"], \"left\") \\\n",
    "           .select( \\\n",
    "                col(\"codtribunal\"), col(\"grau\"), col(\"millisinsercao\"), col(\"codclasse\"), col(\"descclasse\"), \\\n",
    "                col(\"codlocalidade\"), col(\"competencia\"), col(\"dtajuizamento\"), col(\"descsistema\"), \\\n",
    "                col(\"nivelsigilo\"), col(\"npu\"), col(\"valorcausa\"), col(\"tramitacao\"), col(\"tamanhoprocesso\"), \\\n",
    "                col(\"oj_codibge\"), col(\"oj_cod\"), col(\"oj_instancia\"), col(\"oj_descricao\"), \\\n",
    "                col(\"mov_dtmov\"), col(\"mov_cod\"), col(\"descmovimento\"), col(\"mov_codlocal\"), \\\n",
    "                col(\"mov_codpainacional\"), col(\"mov_nivelsigilo\"), col(\"mov_oj_codibge\"), \\\n",
    "                col(\"mov_oj_cod\"), col(\"mov_oj_instancia\"), col(\"mov_oj_descricao\"), col(\"mov_tpdecisao\"), \\\n",
    "                col(\"mov_tprespmov\") \\\n",
    "        )\n",
    "        \n",
    "        #df_query_distinctPd = df_query_processo_movimento.toPandas()\n",
    "        #df_query_distinctPd.to_csv('./output/movimentos_tribunais.csv', mode='a', header=is_first, sep = \";\", index=False, chunksize=1000)\n",
    "        \n",
    "        df_query_processo_movimento = df_query_processo_movimento.withColumn('mov_dtmov', to_timestamp(df_query_processo_movimento['mov_dtmov'], 'yyyyMMddHHmmss'))\n",
    "        \n",
    "        if is_first == True:\n",
    "            is_first = False\n",
    "            \n",
    "            df_query_processo_assunto.repartition(5).write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.processo_assunto\") \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "            \n",
    "            df_query_processo_movimento.repartition(5).write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.fat_movimento_\" + sufixo_tabela) \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "        else :\n",
    "            \n",
    "            df_query_processo_assunto.repartition(5).write \\\n",
    "                .mode(\"append\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.processo_assunto\") \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "            \n",
    "            df_query_processo_movimento.repartition(5).write \\\n",
    "                .mode(\"append\") \\\n",
    "                .format(\"jdbc\") \\\n",
    "                .option(\"url\", db_url).option(\"user\", db_user).option(\"password\", db_pass).option(\"driver\", db_driver) \\\n",
    "                .option(\"dbtable\", \"inovacnj.fat_movimento_\" + sufixo_tabela) \\\n",
    "                .option(\"batchsize\", \"10000\") \\\n",
    "                .save()\n",
    "\n",
    "        print(\"Finalizando carregamento do tribunal: \" + dir_trib)\n",
    "        \n",
    "    print(\"Finalizando carregamento do ramo de justica: \" + dir_ramo_just)\n",
    "    \n",
    "print(\"Carregamento dos arquivos finalizado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
